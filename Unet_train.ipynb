{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data\n",
    "import models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.data_path= 'data'\n",
    "        self.dataset= 'masked_pwc'\n",
    "        self.batch_size= 32\n",
    "        self.model= 'unet1d'\n",
    "        self.lr= 0.001\n",
    "        self.num_epochs= 100\n",
    "        self.n_data = 100000\n",
    "        self.min_sep = 5\n",
    "        self.valid_interval= 1\n",
    "        self.save_interval= 1\n",
    "        self.seed = 0\n",
    "        self.output_dir= 'experiments'\n",
    "        self.experiment= None\n",
    "        self.resume_training= False\n",
    "        self.restore_file= None\n",
    "        self.no_save= False\n",
    "        self.step_checkpoints= False\n",
    "        self.no_log= False\n",
    "        self.log_interval= 100\n",
    "        self.no_visual= False\n",
    "        self.visual_interval= 100\n",
    "        self.no_progress= False\n",
    "        self.draft= False\n",
    "        self.dry_run= False\n",
    "        self.in_channels= 1\n",
    "        self.bias= False\n",
    "        self.test_num = 0\n",
    "        # UNET\n",
    "        self.residual = False\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-08-20 09:29:41] COMMAND: /home/michael/python-virtual-environments/bfcnn/lib/python3.6/site-packages/ipykernel_launcher.py -f /home/michael/.local/share/jupyter/runtime/kernel-630f7d19-217f-468c-994c-4fd48aa9dcc4.json\n",
      "[2020-08-20 09:29:41] Arguments: {'data_path': 'data', 'dataset': 'masked_pwc', 'batch_size': 32, 'model': 'unet1d', 'lr': 0.001, 'num_epochs': 100, 'n_data': 100000, 'min_sep': 5, 'valid_interval': 1, 'save_interval': 1, 'seed': 0, 'output_dir': 'experiments', 'experiment': 'unet1d-Aug-20-09:29:41', 'resume_training': False, 'restore_file': None, 'no_save': False, 'step_checkpoints': False, 'no_log': False, 'log_interval': 100, 'no_visual': False, 'visual_interval': 100, 'no_progress': False, 'draft': False, 'dry_run': False, 'in_channels': 1, 'bias': False, 'test_num': 0, 'residual': False, 'experiment_dir': 'experiments/unet1d/unet1d-Aug-20-09:29:41', 'checkpoint_dir': 'experiments/unet1d/unet1d-Aug-20-09:29:41/checkpoints', 'log_dir': 'experiments/unet1d/unet1d-Aug-20-09:29:41/logs', 'log_file': 'experiments/unet1d/unet1d-Aug-20-09:29:41/logs/train.log'}\n"
     ]
    }
   ],
   "source": [
    "# gpu or cpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "utils.setup_experiment(args)\n",
    "utils.init_logging(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-08-20 09:29:59] Built a model consisting of 72,000 parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (conv1): PartialConv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "  (conv2): PartialConv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv3): PartialConv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "  (conv4): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv5): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
      "  (conv6): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
      "  (conv7): ConvTranspose1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "  (conv8): PartialConv1d(96, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv9): PartialConv1d(32, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Saving model\n",
    "# torch.save(model.state_dict(), MODEL_PATH)\n",
    "# MODEL_PATH = \"models/trained/dncnn1d_partialconv_5kdata_20epoch_08_12_20.pth\"\n",
    "MODEL_PATH = \"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"\n",
    "\n",
    "train_new_model = True\n",
    "\n",
    "\n",
    "\n",
    "# Build data loaders, a model and an optimizer\n",
    "if train_new_model:\n",
    "    model = models.build_model(args).to(device)\n",
    "else:\n",
    "    model = models.build_model(args)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 60, 70, 80, 90, 100], gamma=0.5)\n",
    "logging.info(f\"Built a model consisting of {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "if args.resume_training:\n",
    "    state_dict = utils.load_checkpoint(args, model, optimizer, scheduler)\n",
    "    global_step = state_dict['last_step']\n",
    "    start_epoch = int(state_dict['last_step']/(403200/state_dict['args'].batch_size))+1\n",
    "else:\n",
    "    global_step = -1\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_dataset is a function in utils/data/__init__.py\n",
    "train_loader, valid_loader, _ = data.build_dataset(args.dataset,\n",
    "                                                   args.n_data, \n",
    "                                                   batch_size=args.batch_size,\n",
    "                                                   min_sep = args.min_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track moving average of loss values\n",
    "train_meters = {name: utils.RunningAverageMeter(0.98) for name in ([\"train_loss\", \"train_psnr\", \"train_ssim\"])}\n",
    "valid_meters = {name: utils.AverageMeter() for name in ([\"valid_psnr\", \"valid_ssim\"])}\n",
    "writer = SummaryWriter(log_dir=args.experiment_dir) if not args.no_visual else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-08-20 09:37:50] epoch 00 | train_loss 0.151 | train_psnr 28.743 | train_ssim 0.908 | valid_psnr 28.927 | valid_ssim 0.907 | lr 1.0e-03             \n",
      "[2020-08-20 09:45:27] epoch 01 | train_loss 0.147 | train_psnr 28.989 | train_ssim 0.909 | valid_psnr 29.361 | valid_ssim 0.911 | lr 1.0e-03             \n",
      "[2020-08-20 09:52:50] epoch 02 | train_loss 0.135 | train_psnr 29.441 | train_ssim 0.911 | valid_psnr 29.770 | valid_ssim 0.914 | lr 1.0e-03             \n",
      "[2020-08-20 10:00:14] epoch 03 | train_loss 0.138 | train_psnr 29.494 | train_ssim 0.911 | valid_psnr 29.768 | valid_ssim 0.913 | lr 1.0e-03             \n",
      "[2020-08-20 10:07:37] epoch 04 | train_loss 0.144 | train_psnr 29.409 | train_ssim 0.911 | valid_psnr 29.719 | valid_ssim 0.912 | lr 1.0e-03             \n",
      "[2020-08-20 10:15:00] epoch 05 | train_loss 0.140 | train_psnr 29.619 | train_ssim 0.911 | valid_psnr 29.845 | valid_ssim 0.913 | lr 1.0e-03             \n",
      "[2020-08-20 10:22:24] epoch 06 | train_loss 0.144 | train_psnr 29.689 | train_ssim 0.912 | valid_psnr 29.990 | valid_ssim 0.913 | lr 1.0e-03             \n",
      "[2020-08-20 10:29:47] epoch 07 | train_loss 0.141 | train_psnr 29.398 | train_ssim 0.911 | valid_psnr 29.399 | valid_ssim 0.912 | lr 1.0e-03             \n",
      "[2020-08-20 10:37:10] epoch 08 | train_loss 0.138 | train_psnr 29.830 | train_ssim 0.913 | valid_psnr 29.849 | valid_ssim 0.913 | lr 1.0e-03             \n",
      "[2020-08-20 10:44:33] epoch 09 | train_loss 0.132 | train_psnr 29.850 | train_ssim 0.914 | valid_psnr 30.230 | valid_ssim 0.914 | lr 1.0e-03             \n",
      "[2020-08-20 10:51:56] epoch 10 | train_loss 0.137 | train_psnr 29.579 | train_ssim 0.913 | valid_psnr 30.148 | valid_ssim 0.914 | lr 1.0e-03             \n",
      "[2020-08-20 10:59:18] epoch 11 | train_loss 0.140 | train_psnr 29.390 | train_ssim 0.911 | valid_psnr 29.099 | valid_ssim 0.912 | lr 1.0e-03             \n",
      "[2020-08-20 11:06:44] epoch 12 | train_loss 0.133 | train_psnr 30.117 | train_ssim 0.915 | valid_psnr 29.729 | valid_ssim 0.913 | lr 1.0e-03             \n",
      "[2020-08-20 11:14:10] epoch 13 | train_loss 0.141 | train_psnr 29.607 | train_ssim 0.912 | valid_psnr 29.758 | valid_ssim 0.913 | lr 1.0e-03             \n",
      "[2020-08-20 11:21:34] epoch 14 | train_loss 0.139 | train_psnr 29.862 | train_ssim 0.913 | valid_psnr 30.405 | valid_ssim 0.917 | lr 1.0e-03             \n",
      "[2020-08-20 11:28:56] epoch 15 | train_loss 0.136 | train_psnr 30.097 | train_ssim 0.915 | valid_psnr 30.406 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 11:36:18] epoch 16 | train_loss 0.136 | train_psnr 30.179 | train_ssim 0.915 | valid_psnr 30.600 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 11:43:39] epoch 17 | train_loss 0.137 | train_psnr 29.971 | train_ssim 0.913 | valid_psnr 30.127 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 11:51:15] epoch 18 | train_loss 0.138 | train_psnr 30.025 | train_ssim 0.914 | valid_psnr 30.469 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 11:58:52] epoch 19 | train_loss 0.131 | train_psnr 29.959 | train_ssim 0.916 | valid_psnr 29.927 | valid_ssim 0.913 | lr 1.0e-03             \n",
      "[2020-08-20 12:06:18] epoch 20 | train_loss 0.132 | train_psnr 30.184 | train_ssim 0.915 | valid_psnr 30.460 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 12:13:42] epoch 21 | train_loss 0.132 | train_psnr 30.144 | train_ssim 0.914 | valid_psnr 30.287 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 12:21:04] epoch 22 | train_loss 0.141 | train_psnr 29.816 | train_ssim 0.912 | valid_psnr 29.979 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 12:28:26] epoch 23 | train_loss 0.139 | train_psnr 30.180 | train_ssim 0.915 | valid_psnr 30.492 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 12:35:49] epoch 24 | train_loss 0.134 | train_psnr 29.890 | train_ssim 0.913 | valid_psnr 30.356 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 12:43:11] epoch 25 | train_loss 0.141 | train_psnr 29.643 | train_ssim 0.912 | valid_psnr 30.386 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 12:50:34] epoch 26 | train_loss 0.138 | train_psnr 29.880 | train_ssim 0.913 | valid_psnr 29.906 | valid_ssim 0.914 | lr 1.0e-03             \n",
      "[2020-08-20 12:58:07] epoch 27 | train_loss 0.142 | train_psnr 30.067 | train_ssim 0.913 | valid_psnr 29.512 | valid_ssim 0.911 | lr 1.0e-03             \n",
      "[2020-08-20 13:05:45] epoch 28 | train_loss 0.141 | train_psnr 30.126 | train_ssim 0.914 | valid_psnr 29.938 | valid_ssim 0.914 | lr 1.0e-03             \n",
      "[2020-08-20 13:13:11] epoch 29 | train_loss 0.135 | train_psnr 29.976 | train_ssim 0.914 | valid_psnr 28.930 | valid_ssim 0.910 | lr 1.0e-03             \n",
      "[2020-08-20 13:20:51] epoch 30 | train_loss 0.136 | train_psnr 29.885 | train_ssim 0.914 | valid_psnr 30.432 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 13:28:22] epoch 31 | train_loss 0.146 | train_psnr 29.838 | train_ssim 0.913 | valid_psnr 30.166 | valid_ssim 0.914 | lr 1.0e-03             \n",
      "[2020-08-20 13:36:00] epoch 32 | train_loss 0.137 | train_psnr 29.954 | train_ssim 0.914 | valid_psnr 30.343 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 13:43:46] epoch 33 | train_loss 0.134 | train_psnr 30.355 | train_ssim 0.917 | valid_psnr 30.454 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 13:51:09] epoch 34 | train_loss 0.141 | train_psnr 29.896 | train_ssim 0.912 | valid_psnr 30.340 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 13:58:32] epoch 35 | train_loss 0.136 | train_psnr 30.007 | train_ssim 0.915 | valid_psnr 30.574 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 14:05:55] epoch 36 | train_loss 0.130 | train_psnr 30.370 | train_ssim 0.916 | valid_psnr 30.741 | valid_ssim 0.917 | lr 1.0e-03             \n",
      "[2020-08-20 14:13:17] epoch 37 | train_loss 0.135 | train_psnr 30.348 | train_ssim 0.916 | valid_psnr 30.339 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 14:20:39] epoch 38 | train_loss 0.128 | train_psnr 30.208 | train_ssim 0.916 | valid_psnr 30.688 | valid_ssim 0.917 | lr 1.0e-03             \n",
      "[2020-08-20 14:28:01] epoch 39 | train_loss 0.132 | train_psnr 30.515 | train_ssim 0.917 | valid_psnr 30.791 | valid_ssim 0.917 | lr 1.0e-03             \n",
      "[2020-08-20 14:35:22] epoch 40 | train_loss 0.141 | train_psnr 29.847 | train_ssim 0.913 | valid_psnr 30.164 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 14:42:44] epoch 41 | train_loss 0.132 | train_psnr 30.341 | train_ssim 0.914 | valid_psnr 29.865 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 14:50:06] epoch 42 | train_loss 0.130 | train_psnr 30.361 | train_ssim 0.915 | valid_psnr 30.564 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 14:57:27] epoch 43 | train_loss 0.132 | train_psnr 30.556 | train_ssim 0.916 | valid_psnr 30.787 | valid_ssim 0.917 | lr 1.0e-03             \n",
      "[2020-08-20 15:04:49] epoch 44 | train_loss 0.143 | train_psnr 30.021 | train_ssim 0.915 | valid_psnr 28.821 | valid_ssim 0.909 | lr 1.0e-03             \n",
      "[2020-08-20 15:12:11] epoch 45 | train_loss 0.136 | train_psnr 30.083 | train_ssim 0.915 | valid_psnr 30.100 | valid_ssim 0.914 | lr 1.0e-03             \n",
      "[2020-08-20 15:19:32] epoch 46 | train_loss 0.125 | train_psnr 30.750 | train_ssim 0.917 | valid_psnr 30.356 | valid_ssim 0.915 | lr 1.0e-03             \n",
      "[2020-08-20 15:26:53] epoch 47 | train_loss 0.130 | train_psnr 30.414 | train_ssim 0.916 | valid_psnr 30.839 | valid_ssim 0.917 | lr 1.0e-03             \n",
      "[2020-08-20 15:34:15] epoch 48 | train_loss 0.140 | train_psnr 30.095 | train_ssim 0.913 | valid_psnr 30.615 | valid_ssim 0.916 | lr 1.0e-03             \n",
      "[2020-08-20 15:41:36] epoch 49 | train_loss 0.131 | train_psnr 30.446 | train_ssim 0.916 | valid_psnr 30.715 | valid_ssim 0.918 | lr 1.0e-03             \n",
      "[2020-08-20 15:48:57] epoch 50 | train_loss 0.132 | train_psnr 30.609 | train_ssim 0.916 | valid_psnr 30.092 | valid_ssim 0.916 | lr 5.0e-04             \n",
      "[2020-08-20 15:56:18] epoch 51 | train_loss 0.134 | train_psnr 30.930 | train_ssim 0.918 | valid_psnr 30.466 | valid_ssim 0.916 | lr 5.0e-04             \n",
      "[2020-08-20 16:03:42] epoch 52 | train_loss 0.130 | train_psnr 30.739 | train_ssim 0.916 | valid_psnr 30.721 | valid_ssim 0.918 | lr 5.0e-04             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-08-20 16:11:04] epoch 53 | train_loss 0.137 | train_psnr 30.705 | train_ssim 0.916 | valid_psnr 30.846 | valid_ssim 0.917 | lr 5.0e-04             \n",
      "[2020-08-20 16:18:26] epoch 54 | train_loss 0.133 | train_psnr 30.930 | train_ssim 0.919 | valid_psnr 30.459 | valid_ssim 0.917 | lr 5.0e-04             \n",
      "[2020-08-20 16:25:48] epoch 55 | train_loss 0.134 | train_psnr 30.871 | train_ssim 0.917 | valid_psnr 30.693 | valid_ssim 0.917 | lr 5.0e-04             \n",
      "[2020-08-20 16:33:28] epoch 56 | train_loss 0.139 | train_psnr 30.579 | train_ssim 0.915 | valid_psnr 30.872 | valid_ssim 0.917 | lr 5.0e-04             \n",
      "[2020-08-20 16:41:07] epoch 57 | train_loss 0.132 | train_psnr 30.707 | train_ssim 0.917 | valid_psnr 30.901 | valid_ssim 0.918 | lr 5.0e-04             \n",
      "[2020-08-20 16:48:47] epoch 58 | train_loss 0.128 | train_psnr 30.844 | train_ssim 0.919 | valid_psnr 30.913 | valid_ssim 0.918 | lr 5.0e-04             \n",
      "[2020-08-20 16:56:17] epoch 59 | train_loss 0.127 | train_psnr 30.813 | train_ssim 0.919 | valid_psnr 30.866 | valid_ssim 0.917 | lr 5.0e-04             \n",
      "[2020-08-20 17:03:43] epoch 60 | train_loss 0.132 | train_psnr 31.184 | train_ssim 0.919 | valid_psnr 31.214 | valid_ssim 0.918 | lr 2.5e-04             \n",
      "[2020-08-20 17:11:08] epoch 61 | train_loss 0.132 | train_psnr 31.240 | train_ssim 0.919 | valid_psnr 31.134 | valid_ssim 0.918 | lr 2.5e-04             \n",
      "[2020-08-20 17:18:31] epoch 62 | train_loss 0.138 | train_psnr 31.004 | train_ssim 0.916 | valid_psnr 31.321 | valid_ssim 0.918 | lr 2.5e-04             \n",
      "[2020-08-20 17:25:54] epoch 63 | train_loss 0.137 | train_psnr 31.256 | train_ssim 0.919 | valid_psnr 31.324 | valid_ssim 0.918 | lr 2.5e-04             \n",
      "[2020-08-20 17:33:18] epoch 64 | train_loss 0.128 | train_psnr 31.142 | train_ssim 0.919 | valid_psnr 31.164 | valid_ssim 0.918 | lr 2.5e-04             \n",
      "[2020-08-20 17:40:42] epoch 65 | train_loss 0.136 | train_psnr 31.022 | train_ssim 0.918 | valid_psnr 31.033 | valid_ssim 0.918 | lr 2.5e-04             \n",
      "[2020-08-20 17:48:06] epoch 66 | train_loss 0.131 | train_psnr 30.957 | train_ssim 0.918 | valid_psnr 31.239 | valid_ssim 0.918 | lr 2.5e-04             \n",
      "[2020-08-20 17:55:30] epoch 67 | train_loss 0.130 | train_psnr 31.167 | train_ssim 0.918 | valid_psnr 31.227 | valid_ssim 0.918 | lr 2.5e-04             \n",
      "[2020-08-20 18:02:55] epoch 68 | train_loss 0.130 | train_psnr 31.361 | train_ssim 0.919 | valid_psnr 31.335 | valid_ssim 0.919 | lr 2.5e-04             \n",
      "[2020-08-20 18:10:21] epoch 69 | train_loss 0.134 | train_psnr 31.026 | train_ssim 0.918 | valid_psnr 30.788 | valid_ssim 0.917 | lr 2.5e-04             \n",
      "[2020-08-20 18:17:44] epoch 70 | train_loss 0.132 | train_psnr 31.052 | train_ssim 0.917 | valid_psnr 31.383 | valid_ssim 0.918 | lr 1.3e-04             \n",
      "[2020-08-20 18:25:08] epoch 71 | train_loss 0.127 | train_psnr 31.816 | train_ssim 0.921 | valid_psnr 31.351 | valid_ssim 0.918 | lr 1.3e-04             \n",
      "[2020-08-20 18:32:33] epoch 72 | train_loss 0.133 | train_psnr 31.319 | train_ssim 0.918 | valid_psnr 31.359 | valid_ssim 0.918 | lr 1.3e-04             \n",
      "[2020-08-20 18:39:57] epoch 73 | train_loss 0.137 | train_psnr 31.389 | train_ssim 0.918 | valid_psnr 31.468 | valid_ssim 0.919 | lr 1.3e-04             \n",
      "[2020-08-20 18:47:21] epoch 74 | train_loss 0.129 | train_psnr 31.402 | train_ssim 0.920 | valid_psnr 31.278 | valid_ssim 0.918 | lr 1.3e-04             \n",
      "[2020-08-20 18:54:45] epoch 75 | train_loss 0.135 | train_psnr 31.030 | train_ssim 0.918 | valid_psnr 31.452 | valid_ssim 0.919 | lr 1.3e-04             \n",
      "[2020-08-20 19:02:10] epoch 76 | train_loss 0.129 | train_psnr 31.366 | train_ssim 0.919 | valid_psnr 31.170 | valid_ssim 0.918 | lr 1.3e-04             \n",
      "[2020-08-20 19:09:36] epoch 77 | train_loss 0.138 | train_psnr 31.311 | train_ssim 0.918 | valid_psnr 31.480 | valid_ssim 0.919 | lr 1.3e-04             \n",
      "[2020-08-20 19:17:00] epoch 78 | train_loss 0.126 | train_psnr 31.758 | train_ssim 0.921 | valid_psnr 31.517 | valid_ssim 0.919 | lr 1.3e-04             \n",
      "[2020-08-20 19:24:25] epoch 79 | train_loss 0.128 | train_psnr 31.391 | train_ssim 0.919 | valid_psnr 31.349 | valid_ssim 0.918 | lr 1.3e-04             \n",
      "[2020-08-20 19:31:50] epoch 80 | train_loss 0.130 | train_psnr 31.323 | train_ssim 0.919 | valid_psnr 31.269 | valid_ssim 0.918 | lr 6.3e-05             \n",
      "[2020-08-20 19:39:14] epoch 81 | train_loss 0.130 | train_psnr 31.278 | train_ssim 0.919 | valid_psnr 31.570 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 19:46:38] epoch 82 | train_loss 0.124 | train_psnr 31.748 | train_ssim 0.921 | valid_psnr 31.443 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 19:54:04] epoch 83 | train_loss 0.127 | train_psnr 31.785 | train_ssim 0.919 | valid_psnr 31.507 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 20:01:29] epoch 84 | train_loss 0.131 | train_psnr 31.595 | train_ssim 0.918 | valid_psnr 31.416 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 20:08:54] epoch 85 | train_loss 0.126 | train_psnr 31.463 | train_ssim 0.919 | valid_psnr 31.485 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 20:16:19] epoch 86 | train_loss 0.129 | train_psnr 31.624 | train_ssim 0.919 | valid_psnr 31.493 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 20:23:43] epoch 87 | train_loss 0.126 | train_psnr 31.773 | train_ssim 0.920 | valid_psnr 31.584 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 20:31:08] epoch 88 | train_loss 0.132 | train_psnr 31.733 | train_ssim 0.919 | valid_psnr 31.572 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 20:38:32] epoch 89 | train_loss 0.126 | train_psnr 31.552 | train_ssim 0.919 | valid_psnr 31.582 | valid_ssim 0.919 | lr 6.3e-05             \n",
      "[2020-08-20 20:45:57] epoch 90 | train_loss 0.126 | train_psnr 31.842 | train_ssim 0.920 | valid_psnr 31.592 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 20:53:20] epoch 91 | train_loss 0.134 | train_psnr 31.342 | train_ssim 0.917 | valid_psnr 31.642 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:00:45] epoch 92 | train_loss 0.132 | train_psnr 31.427 | train_ssim 0.919 | valid_psnr 31.605 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:08:08] epoch 93 | train_loss 0.128 | train_psnr 31.397 | train_ssim 0.918 | valid_psnr 31.656 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:15:32] epoch 94 | train_loss 0.133 | train_psnr 31.455 | train_ssim 0.917 | valid_psnr 31.579 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:22:55] epoch 95 | train_loss 0.133 | train_psnr 31.597 | train_ssim 0.919 | valid_psnr 31.543 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:30:19] epoch 96 | train_loss 0.125 | train_psnr 32.148 | train_ssim 0.921 | valid_psnr 31.602 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:37:42] epoch 97 | train_loss 0.123 | train_psnr 31.501 | train_ssim 0.919 | valid_psnr 31.548 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:45:06] epoch 98 | train_loss 0.128 | train_psnr 31.687 | train_ssim 0.919 | valid_psnr 31.624 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:52:29] epoch 99 | train_loss 0.123 | train_psnr 31.806 | train_ssim 0.921 | valid_psnr 31.637 | valid_ssim 0.919 | lr 3.1e-05             \n",
      "[2020-08-20 21:52:29] Done training! Best PSNR 31.656 obtained after step 293749.\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "for epoch in range(start_epoch, args.num_epochs):\n",
    "    if args.resume_training:\n",
    "        if epoch %10 == 0:\n",
    "            optimizer.param_groups[0][\"lr\"] /= 2\n",
    "            print('learning rate reduced by factor of 2')\n",
    "\n",
    "    train_bar = utils.ProgressBar(train_loader, epoch)\n",
    "    for meter in train_meters.values():\n",
    "        meter.reset()\n",
    "\n",
    "    for batch_id, (clean, mask) in enumerate(train_bar):\n",
    "        # dataloader returns [clean, mask] list\n",
    "        model.train()\n",
    "        global_step += 1\n",
    "        inputs = clean.to(device)\n",
    "        mask_inputs = mask.to(device)\n",
    "        # only use the mask part of the outputs\n",
    "        raw_outputs = model(inputs,mask_inputs)\n",
    "        outputs = (1-mask_inputs)*raw_outputs + mask_inputs*inputs\n",
    "        \n",
    "        # TO DO, only run loss on masked part of output\n",
    "        loss = F.mse_loss(outputs, inputs, reduction=\"sum\") / (inputs.size(0) * 2)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_psnr = utils.psnr(outputs, inputs)\n",
    "        train_ssim = utils.ssim(outputs, inputs)\n",
    "        train_meters[\"train_loss\"].update(loss.item())\n",
    "        train_meters[\"train_psnr\"].update(train_psnr.item())\n",
    "        train_meters[\"train_ssim\"].update(train_ssim.item())\n",
    "        train_bar.log(dict(**train_meters, lr=optimizer.param_groups[0][\"lr\"]), verbose=True)\n",
    "\n",
    "        if writer is not None and global_step % args.log_interval == 0:\n",
    "            writer.add_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], global_step)\n",
    "            writer.add_scalar(\"loss/train\", loss.item(), global_step)\n",
    "            writer.add_scalar(\"psnr/train\", train_psnr.item(), global_step)\n",
    "            writer.add_scalar(\"ssim/train\", train_ssim.item(), global_step)\n",
    "            gradients = torch.cat([p.grad.view(-1) for p in model.parameters() if p.grad is not None], dim=0)\n",
    "            writer.add_histogram(\"gradients\", gradients, global_step)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    if epoch % args.valid_interval == 0:\n",
    "        model.eval()\n",
    "        for meter in valid_meters.values():\n",
    "            meter.reset()\n",
    "\n",
    "        valid_bar = utils.ProgressBar(valid_loader)\n",
    "        \n",
    "        for sample_id, (clean, mask) in enumerate(valid_bar):\n",
    "            with torch.no_grad():\n",
    "                inputs = clean.to(device)\n",
    "                mask_inputs = mask.to(device)\n",
    "                # only use the mask part of the outputs\n",
    "                raw_output = model(inputs,mask_inputs)\n",
    "                output = (1-mask_inputs)*raw_output + mask_inputs*inputs\n",
    "#                 output = model(inputs)\n",
    "#                 sample = noisy_clean_sample[1].to(device)\n",
    "#                 noisy_inputs = noisy_clean_sample[0].to(device);\n",
    "#                 output = model(noisy_inputs)\n",
    "\n",
    "                valid_psnr = utils.psnr(inputs, output)\n",
    "                valid_meters[\"valid_psnr\"].update(valid_psnr.item())\n",
    "                valid_ssim = utils.ssim(inputs, output)\n",
    "                valid_meters[\"valid_ssim\"].update(valid_ssim.item())\n",
    "\n",
    "                ### Uncomment these when finished\n",
    "                if writer is not None and sample_id < 10:\n",
    "                    image = torch.cat([inputs, torch.mul(inputs, mask_inputs), output], dim=0)\n",
    "                    image = torchvision.utils.make_grid(image.clamp(0, 1), nrow=3, normalize=False)\n",
    "                    writer.add_image(f\"valid_samples/{sample_id}\", image, global_step)\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"psnr/valid\", valid_meters['valid_psnr'].avg, global_step)\n",
    "            writer.add_scalar(\"ssim/valid\", valid_meters['valid_ssim'].avg, global_step)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        logging.info(train_bar.print(dict(**train_meters, **valid_meters, lr=optimizer.param_groups[0][\"lr\"])))\n",
    "        utils.save_checkpoint(args, global_step, model, optimizer, score=valid_meters[\"valid_psnr\"].avg, mode=\"max\")\n",
    "    scheduler.step()\n",
    "\n",
    "logging.info(f\"Done training! Best PSNR {utils.save_checkpoint.best_score:.3f} obtained after step {utils.save_checkpoint.best_step}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = models.build_model(args)\n",
    "# model3.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"))\n",
    "# model3.to(device)\n",
    "\n",
    "# model5 = models.build_model(args)\n",
    "# model5.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_08_13_20.pth\"))\n",
    "# model5.to(device)\n",
    "\n",
    "model10 = models.build_model(args)\n",
    "model10.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_10minsep_08_14_20.pth\"))\n",
    "model10.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of first predicted point\n",
    "Comparison to global mean, receptive field mean, next visible point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_sep = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def first_pt_stats(model,min_sep):\n",
    "    _,_,test_loader = data.build_dataset(args.dataset,\n",
    "                                                   args.n_data, \n",
    "                                                   batch_size=args.n_data,\n",
    "                                                   fix_datapoints=True,            \n",
    "                                                   min_sep = min_sep,\n",
    "                                                   test_num = 1)\n",
    "    print(\"Min_sep: {}\".format(min_sep))\n",
    "    print(\"*\"*30)\n",
    "    for batch_id,(clean,mask) in enumerate(test_loader):\n",
    "        print(\"Mean of clean signal: {:2.4f}\".format(clean.mean()))\n",
    "        outputs = model(clean.to(device),mask.to(device)).cpu()\n",
    "        print(\"Mean first value (min_sep=3): {:2.4f}\".format(outputs[:,:,0].mean()))\n",
    "\n",
    "    # Collect the \"means\" we're comparing to\n",
    "    mean_unmasked_sig = []\n",
    "    mean_rf_sig = []\n",
    "    first_unmasked = []\n",
    "\n",
    "    # Collect the diffs with the first value\n",
    "    mean_unmasked_sig_diff = []\n",
    "    mean_rf_sig_diff = []\n",
    "    first_unmasked_diff = []\n",
    "\n",
    "    mask_length = (64-mask.sum(axis=2))\n",
    "    for i in range(len(mask_length)):\n",
    "        # Mean of unmasked signal\n",
    "        mum = clean[i,0,int(mask_length[i]):].mean()\n",
    "        mean_unmasked_sig.append(mum)\n",
    "        # Mean of the unmasked receptive field \n",
    "        mrf = clean[i,0,int(mask_length[i]):21].mean()\n",
    "        mean_rf_sig.append(mrf)\n",
    "        # First unmasked value\n",
    "        fu = clean[i,0,int(mask_length[i])]\n",
    "        first_unmasked.append(fu)\n",
    "\n",
    "        # The diffs\n",
    "        mean_unmasked_sig_diff.append(abs(outputs[i,0,0]-mum).detach())\n",
    "        mean_rf_sig_diff.append(abs(outputs[i,0,0]-mrf).detach())\n",
    "        first_unmasked_diff.append(abs(outputs[i,0,0]-fu).detach())\n",
    "\n",
    "    print(\"Mean of full unmasked signal: {:2.4f}\".format(np.mean(mean_unmasked_sig)))\n",
    "    print(\"Mean of receptive field signal [0,21]: {:2.4f}\".format(np.mean(mean_rf_sig)))\n",
    "    print(\"Mean of first visible value after mask: {:2.4f}\".format(np.mean(first_unmasked)))\n",
    "\n",
    "    print(\"First predicted value mean diff: full unmasked signal: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(mean_unmasked_sig_diff),np.std(mean_unmasked_sig_diff)))\n",
    "    print(\"First predicted value mean diff: receptive field signal [0,21]: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(mean_rf_sig_diff),np.std(mean_rf_sig_diff)))\n",
    "    print(\"First predicted value mean diff: first visible value after mask: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(first_unmasked_diff),np.std(first_unmasked_diff)))\n",
    "    \n",
    "    df_list = [min_sep,np.mean(mean_unmasked_sig),np.mean(mean_rf_sig),np.mean(first_unmasked),\n",
    "              float(outputs[:,:,0].mean().detach()),\n",
    "              np.mean(mean_unmasked_sig_diff),np.std(mean_unmasked_sig_diff),\n",
    "              np.mean(mean_rf_sig_diff),np.std(mean_rf_sig_diff),\n",
    "              np.mean(first_unmasked_diff),np.std(first_unmasked_diff)\n",
    "              ]\n",
    "    # print(\"Mean absolute diff of first predicted value and first visible after mask: {:2.4f}\".format(np.mean(first_pred_unmasked_diff)))\n",
    "    ### min_sep = 3\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list3 = first_pt_stats(model3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list5 = first_pt_stats(model5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_list10 = first_pt_stats(model10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([df_list3,df_list5,df_list10],columns = ['min_sep',\\\n",
    "                                      'clean_sig_mean','receptive_field_mean',\\\n",
    "                                      'first_visible_mean','first_pred_mean',\\\n",
    "                                      'full_unmasked_diff_mean','full_unmasked_diff_sd',\\\n",
    "                                      'receptive_field_diff_mean','receptive_field_diff_sd',\\\n",
    "                                      'first_visible_diff_mean','first_visible_diff_sd'\n",
    "                                     ]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Best PSNR 28.560\n",
    "def mask_idx_f(mask):\n",
    "    mask_start = int(np.argmin(mask[0]))\n",
    "    mask_length = int((1-mask[0]).sum())\n",
    "    mask_idx = range(mask_start,mask_start+mask_length)\n",
    "     # No mask indices\n",
    "    before = np.arange(mask.shape[2])[:mask_start]\n",
    "    after = np.arange(mask.shape[2])[mask_start+mask_length:]\n",
    "    no_mask_idx = np.append(before,after)\n",
    "    return mask_idx,before, after, mask_length, mask_start\n",
    "\n",
    "def print_one(loader,model):\n",
    "    np.random.seed()\n",
    "    clean,mask = next(iter(loader))\n",
    "    outputs = model(clean.to(device),mask.to(device)).cpu()\n",
    "    \n",
    "    mask_idx,before_mask,after_mask,mask_length, mask_start = mask_idx_f(mask)\n",
    "\n",
    "    outputs[0] * (1-mask[0]) + clean[0]*mask[0]    \n",
    "\n",
    "    out = outputs[0] * (1-mask[0]) + clean[0]*mask[0]\n",
    "    print(\"Mask Length: {}\\tMask Start: {}\".format(mask_length,mask_start))\n",
    "    \n",
    "    plt.figure(figsize=[15,10])\n",
    "    plt.subplot(3,1,1)\n",
    "    plt.plot(clean[0,0,:],'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "    plt.title(\"True signal\")\n",
    "\n",
    "    plt.subplot(3,1,2)\n",
    "    masked = clean[0]*mask[0]\n",
    "    masked_plot = masked[:mask_start,]\n",
    "    plt.plot(before_mask,masked[0,before_mask],'xb')\n",
    "    plt.plot(after_mask,masked[0,after_mask],'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "\n",
    "    plt.title(\"Masked signal\")\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.plot(out[0,:].detach(),'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "\n",
    "    plt.title(\"Denoised signal\")\n",
    "    \n",
    "    # Mean of the visible signal\n",
    "    sig_mean = clean[0,0,mask_length:21].mean()\n",
    "    print(\"First mask value: {:2.4f}\\nMean of full signal: {:2.4f}\\nMean of visible signal: {:2.4f}\"\\\n",
    "          .format(out[0,0],clean[0,0,:21].mean(),sig_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loader is shuffled and allows test_num to force a certain mask shape\n",
    "_,_,test_loader = data.build_dataset(args.dataset,\n",
    "                                                   args.n_data, \n",
    "                                                   batch_size=args.n_data,\n",
    "                                                   fix_datapoints=True,            \n",
    "                                                   min_sep = 10,\n",
    "                                                   test_num = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "              1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,1.,0.,0.,0.,0.,0.,0.,0.,0., \n",
    "              0., 1., 1., 1.,1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,m = next(iter(test_loader))\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "MODEL_PATH = \"models/trained/unet1d_partialconv_100kdata_100epoch_08_21_20.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
