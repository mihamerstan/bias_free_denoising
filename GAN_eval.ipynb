{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.serialization import default_restore_location\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data\n",
    "import models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu or cpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_GAN_models(restore_file):\n",
    "    # load state_dict for args\n",
    "    state_dict = torch.load(restore_file, map_location=lambda s, l: default_restore_location(s, \"cpu\"))\n",
    "\n",
    "    # Extract args\n",
    "    args = state_dict['args']\n",
    "\n",
    "    # Initiate models\n",
    "    G,D = models.build_model_gan(args)\n",
    "    netG = G.to(device)\n",
    "    netD = D.to(device)\n",
    "\n",
    "    # Load state_dict\n",
    "    netG.load_state_dict(state_dict['modelG'][0]) # Remove the [0] for future models\n",
    "    netD.load_state_dict(state_dict['modelD'][0])\n",
    "    return netG,netD, args\n",
    "\n",
    "restore_file_GAN= \"experiments/unet1d-Sep-01-23:17:43_GAN_only/checkpoints/checkpoint_best.pt\"\n",
    "restore_file_GANMSE= \"experiments/unet1d-Sep-01-23:18:04_MSE/checkpoints/checkpoint_best.pt\"\n",
    "\n",
    "netG_GAN,netD_GAN,_ = load_GAN_models(restore_file_GAN)\n",
    "netG_GANMSE,netD_GANMSE,args = load_GAN_models(restore_file_GANMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MSE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MSE model\n",
    "mse = models.build_model(args)\n",
    "netMSE = mse.to(device)\n",
    "\n",
    "MODEL_PATH = \"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"\n",
    "netMSE.load_state_dict(torch.load(MODEL_PATH))\n",
    "netMSE.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Best PSNR 28.560\n",
    "def mask_idx_f(mask):\n",
    "    mask_start = int(np.argmin(mask[0]))\n",
    "    mask_length = int((1-mask[0]).sum())\n",
    "    mask_idx = range(mask_start,mask_start+mask_length)\n",
    "     # No mask indices\n",
    "    before = np.arange(mask.shape[2])[:mask_start]\n",
    "    after = np.arange(mask.shape[2])[mask_start+mask_length:]\n",
    "    no_mask_idx = np.append(before,after)\n",
    "    return mask_idx,before, after, mask_length, mask_start\n",
    "\n",
    "def model_outputs(clean,mask,model):\n",
    "    outputs = model(clean.to(device),mask.to(device)).cpu()\n",
    "    out = outputs[0] * (1-mask[0]) + clean[0]*mask[0]\n",
    "    return out\n",
    "\n",
    "    \n",
    "def print_one(loader,model_GAN,model_GANMSE,model_MSE):\n",
    "    np.random.seed()\n",
    "    clean,mask = next(iter(loader))\n",
    "    \n",
    "    mask_idx,before_mask,after_mask,mask_length, mask_start = mask_idx_f(mask)\n",
    "\n",
    "    out_GAN = model_outputs(clean,mask,model_GAN)\n",
    "    out_GAN_MSE = model_outputs(clean,mask,model_GANMSE)\n",
    "    out_MSE = model_outputs(clean,mask,model_MSE)\n",
    "\n",
    "    print(\"Mask Length: {}\\tMask Start: {}\".format(mask_length,mask_start))\n",
    "    \n",
    "    plt.figure(figsize=[21,14])\n",
    "    plt.subplot(5,1,1)\n",
    "    plt.plot(clean[0,0,:],'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "    plt.title(\"True signal\")\n",
    "\n",
    "    plt.subplot(5,1,2)\n",
    "    masked = clean[0]*mask[0]\n",
    "    masked_plot = masked[:mask_start,]\n",
    "    plt.plot(before_mask,masked[0,before_mask],'xb')\n",
    "    plt.plot(after_mask,masked[0,after_mask],'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "    plt.title(\"Masked signal\")\n",
    "\n",
    "    plt.subplot(5,1,3)\n",
    "    plt.plot(out_GAN[0,:].detach(),'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "    plt.title(\"GAN denoised signal\")\n",
    " \n",
    "    plt.subplot(5,1,4)\n",
    "    plt.plot(out_GAN_MSE[0,:].detach(),'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "    plt.title(\"GAN+MSE denoised signal\")\n",
    "    \n",
    "    plt.subplot(5,1,5)\n",
    "    plt.plot(out_MSE[0,:].detach(),'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "    plt.title(\"MSE denoised signal\")\n",
    "#     return out1,out2, clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loader is shuffled and allows test_num to force a certain mask shape\n",
    "_, _, test_loader = data.build_dataset(args.datasetG,\n",
    "                                                   batch_size=1,\n",
    "                                                   fix_datapoints=False,\n",
    "                                                   min_sep = args.min_sep,\n",
    "                                                   test_num = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_one(test_loader,netG_GAN,netG_GANMSE,netMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,netG_GAN,netG_GANMSE,netMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,netG_GAN,netG_GANMSE,netMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,netG_GAN,netG_GANMSE,netMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,netG_GAN,netG_GANMSE,netMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,netG_GAN,netG_GANMSE,netMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Discriminator\n",
    "Pull a few examples, generate fakes, and try both the reals and fakes on the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean,mask = next(iter(test_loader))\n",
    "# test discriminator on clean\n",
    "netD_GANMSE(clean.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "inputs = clean.to(device)\n",
    "mask_inputs = mask.to(device)\n",
    "\n",
    "# only use the mask part of the outputs\n",
    "raw_outputs = netG_GANMSE(inputs,mask_inputs)\n",
    "fake = (1-mask_inputs)*raw_outputs + mask_inputs*inputs\n",
    "\n",
    "label = torch.full((inputs.shape[0],),0,device=device)\n",
    "# Introducing label noise\n",
    "#         label = torch.rand((b_size,),device=device)*(fake_label[1]-fake_label[0])+fake_label[0]\n",
    "\n",
    "# Classify all fake batch with D\n",
    "output = netD_GANMSE(fake.detach()).view(-1)\n",
    "# Calculate D's loss on the all-fake batch\n",
    "errD_fake = criterion(output, label)\n",
    "print(errD_fake.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD_GANMSE(fake.detach()).view(-1)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[4,:,:]*mask_inputs[4,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inputs[4,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[4,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake[4,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
