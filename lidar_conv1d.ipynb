{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data\n",
    "import models, utils\n",
    "\n",
    "import pandas as pd\n",
    "from laspy.file import File\n",
    "from pickle import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as udata\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.data_path= 'data' # not used\n",
    "        self.dataset= 'masked_pwc' # move lidar into datasets\n",
    "        self.batch_size= 32\n",
    "        self.model= 'lstm_unet1d'\n",
    "        self.lr= 0.001\n",
    "        self.num_epochs= 100\n",
    "        self.n_data = 100000 # not used\n",
    "        self.min_sep = 5 # not used\n",
    "        self.valid_interval= 1 \n",
    "        self.save_interval= 1\n",
    "        self.seed = 0\n",
    "        self.output_dir= 'lidar_experiments'\n",
    "        self.experiment= None\n",
    "        self.resume_training= False\n",
    "        self.restore_file= None\n",
    "        self.no_save= False\n",
    "        self.step_checkpoints= False\n",
    "        self.no_log= False\n",
    "        self.log_interval= 100\n",
    "        self.no_visual= False\n",
    "        self.visual_interval= 100\n",
    "        self.no_progress= False\n",
    "        self.draft= False\n",
    "        self.dry_run= False\n",
    "        self.bias= False \n",
    "#         self.in_channels= 1 # maybe 6?\n",
    "        self.test_num = 0\n",
    "        # UNET\n",
    "        self.residual = False\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-15 15:05:57] COMMAND: /home/michael/python-virtual-environments/data/lib/python3.6/site-packages/ipykernel_launcher.py -f /home/michael/.local/share/jupyter/runtime/kernel-f465bba2-0619-4a39-8dfe-97045990b5f5.json\n",
      "[2020-09-15 15:05:57] Arguments: {'data_path': 'data', 'dataset': 'masked_pwc', 'batch_size': 32, 'model': 'lstm_unet1d', 'lr': 0.001, 'num_epochs': 100, 'n_data': 100000, 'min_sep': 5, 'valid_interval': 1, 'save_interval': 1, 'seed': 0, 'output_dir': 'lidar_experiments', 'experiment': 'lstm-unet1d-Sep-15-15:05:57', 'resume_training': False, 'restore_file': None, 'no_save': False, 'step_checkpoints': False, 'no_log': False, 'log_interval': 100, 'no_visual': False, 'visual_interval': 100, 'no_progress': False, 'draft': False, 'dry_run': False, 'bias': False, 'test_num': 0, 'residual': False, 'experiment_dir': 'lidar_experiments/lstm_unet1d/lstm-unet1d-Sep-15-15:05:57', 'checkpoint_dir': 'lidar_experiments/lstm_unet1d/lstm-unet1d-Sep-15-15:05:57/checkpoints', 'log_dir': 'lidar_experiments/lstm_unet1d/lstm-unet1d-Sep-15-15:05:57/logs', 'log_file': 'lidar_experiments/lstm_unet1d/lstm-unet1d-Sep-15-15:05:57/logs/train.log'}\n"
     ]
    }
   ],
   "source": [
    "# gpu or cpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "utils.setup_experiment(args)\n",
    "utils.init_logging(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-15 15:05:59] Built a model consisting of 73,120 parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (conv1): PartialConv1d(6, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "  (conv2): PartialConv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv3): PartialConv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "  (conv4): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv5): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
      "  (conv6): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
      "  (conv7): ConvTranspose1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "  (conv8): PartialConv1d(96, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv9): PartialConv1d(32, 3, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Saving model\n",
    "# torch.save(model.state_dict(), MODEL_PATH)\n",
    "# MODEL_PATH = \"models/trained/dncnn1d_partialconv_5kdata_20epoch_08_12_20.pth\"\n",
    "# MODEL_PATH = \"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"\n",
    "\n",
    "train_new_model = True\n",
    "\n",
    "# Build data loaders, a model and an optimizer\n",
    "if train_new_model:\n",
    "    model = models.build_model(args).to(device)\n",
    "else:\n",
    "    model = models.build_model(args)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=25, gamma=0.5)\n",
    "logging.info(f\"Built a model consisting of {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "if args.resume_training:\n",
    "    state_dict = utils.load_checkpoint(args, model, optimizer, scheduler)\n",
    "    global_step = state_dict['last_step']\n",
    "    start_epoch = int(state_dict['last_step']/(403200/state_dict['args'].batch_size))+1\n",
    "else:\n",
    "    global_step = -1\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data parameters\n",
    "scan_line_gap_break = 7000 # threshold over which scan_gap indicates a new scan line\n",
    "min_pt_count = 1700 # in a scan line, otherwise line not used\n",
    "max_pt_count = 2000 # in a scan line, otherwise line not used\n",
    "num_scan_lines = 150 # to use as training set\n",
    "val_split = 0.2\n",
    "seq_len = 64\n",
    "mask_pts_per_seq = 2\n",
    "\n",
    "# LSTM Model parameters\n",
    "hidden_size = 100 # hidden features\n",
    "num_layers = 2 # Default is 1, 2 is a stacked LSTM\n",
    "output_dim = 3 # x,y,z\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_return_df = pd.read_pickle(\"../../lidar/Data/parking_lot/first_returns_modified_164239.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: x_scaled, y_scaled, and z_scaled MUST be the first 3 features\n",
    "feature_list = [\n",
    "    'x_scaled',\n",
    "    'y_scaled',\n",
    "    'z_scaled',\n",
    "    'scan_line_idx',\n",
    "    'scan_angle_deg',\n",
    "    'abs_scan_angle_deg',\n",
    "    'miss_pts_before'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-15 15:06:02] NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "# miss_pts_before is the count of missing points before the point in question (scan gap / 5 -1)\n",
    "first_return_df['miss_pts_before'] = round((first_return_df['scan_gap']/-5)-1)\n",
    "first_return_df['miss_pts_before'] = [max(0,pt) for pt in first_return_df['miss_pts_before']]\n",
    "\n",
    "# Add 'mask' column, set to one by default\n",
    "first_return_df['mask'] = [1]*first_return_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_pts(first_return_df):\n",
    "    # Create a series with the indices of points after gaps and the number of missing points (max of 5)\n",
    "    miss_pt_ser = first_return_df[(first_return_df['miss_pts_before']>0)&\\\n",
    "                                      (first_return_df['miss_pts_before']<6)]['miss_pts_before']\n",
    "    # miss_pts_arr is an array of zeros that is the dimensions [num_missing_pts,cols_in_df]\n",
    "    miss_pts_arr = np.zeros([int(miss_pt_ser.sum()),first_return_df.shape[1]])\n",
    "    # Create empty series to collect the indices of the missing points\n",
    "    indices = np.ones(int(miss_pt_ser.sum()))\n",
    "\n",
    "    # Fill in the indices, such that they all slot in in order before the index\n",
    "    i=0\n",
    "    for index, row in zip(miss_pt_ser.index,miss_pt_ser):\n",
    "        new_indices = index + np.arange(row)/row-1+.01\n",
    "        indices[i:i+int(row)] = new_indices\n",
    "        i+=int(row)\n",
    "    # Create a Dataframe of the indices and miss_pts_arr\n",
    "    miss_pts_df = pd.DataFrame(miss_pts_arr,index=indices,columns = first_return_df.columns)\n",
    "    miss_pts_df['mask'] = [0]*miss_pts_df.shape[0]\n",
    "    # Fill scan fields with NaN so we can interpolate them\n",
    "    for col in ['scan_angle','scan_angle_deg']:\n",
    "        miss_pts_df[col] = [np.NaN]*miss_pts_df.shape[0]\n",
    "    # Concatenate first_return_df and new df\n",
    "    full_df = first_return_df.append(miss_pts_df, ignore_index=False)\n",
    "    # Resort so that the missing points are interspersed, and then reset the index\n",
    "    full_df = full_df.sort_index().reset_index(drop=True)\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't add these in yet\n",
    "# first_return_df = add_missing_pts(first_return_df)\n",
    "# first_return_df[['scan_angle','scan_angle_deg']] = first_return_df[['scan_angle','scan_angle_deg']].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add abs_scan_angle_deg as a feature\n",
    "first_return_df['abs_scan_angle_deg'] = abs(first_return_df['scan_angle_deg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract tensor of scan lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points per scan line\n",
    "scan_line_pt_count = first_return_df.groupby('scan_line_idx').count()['gps_time']\n",
    "\n",
    "# Identify the indices for points at end of scan lines\n",
    "scan_break_idx = first_return_df[(first_return_df['scan_gap']>scan_line_gap_break)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensor\n",
    "line_count = ((scan_line_pt_count>min_pt_count)&(scan_line_pt_count<max_pt_count)).sum()\n",
    "scan_line_tensor = torch.randn([line_count,min_pt_count,len(feature_list)])\n",
    "\n",
    "# Collect the scan lines longer than min_pt_count\n",
    "# For each, collect the first min_pt_count points\n",
    "i=0\n",
    "for line,count in enumerate(scan_line_pt_count):\n",
    "    if (count>min_pt_count)&(count<max_pt_count):\n",
    "        try:\n",
    "            line_idx = scan_break_idx[line-1]\n",
    "            scan_line_tensor[i,:,:] = torch.Tensor(first_return_df.iloc\\\n",
    "                                      [line_idx:line_idx+min_pt_count][feature_list].values)\n",
    "            i+=1\n",
    "        except RuntimeError:\n",
    "            print(\"line: \",line)\n",
    "            print(\"line_idx: \",line_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_tensor(tensor):\n",
    "    # Function takes a 3-D tensor, performs minmax scaling to [0,1] along the third dimension.\n",
    "    # First 2 dimensions are flattened\n",
    "    a,b,c = tensor.shape\n",
    "    # Flatten first two dimensions\n",
    "    flat_tensor = tensor.view(-1,c)\n",
    "    sc =  MinMaxScaler()\n",
    "    flat_norm_tensor = sc.fit_transform(flat_tensor)\n",
    "    # Reshape to original\n",
    "    output = flat_norm_tensor.reshape([a,b,c])\n",
    "    return torch.Tensor(output), sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_line_tensor_norm, sc = min_max_tensor(scan_line_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(data,min_pt_count,seq_len,num_scan_lines,val_split,starting_line=1000):\n",
    "    '''\n",
    "    Function generates training and validation samples for predicting the next point in the sequence.\n",
    "    Inputs:\n",
    "        data: 3-Tensor with dimensions: i) the number of viable scan lines in the flight pass, \n",
    "                                        ii) the minimum number of points in the scan line,\n",
    "                                        iii) 3 (xyz, or feature count)\n",
    "    \n",
    "    '''\n",
    "    # Create generic x tensor\n",
    "    x = torch.ones([(min_pt_count-seq_len)*num_scan_lines,seq_len,len(feature_list)]) \n",
    "    i=0\n",
    "    # Cycle through the number of scan lines requested, starting somewhere in the middle\n",
    "    for line_idx in range(starting_line,starting_line+num_scan_lines):\n",
    "        x = sliding_windows(data[line_idx,:,:],seq_len,line_idx-starting_line, x)\n",
    "\n",
    "    # Remove sequences with missing points\n",
    "    x = x[x[:,:,6].sum(axis=1)==0.]\n",
    "    \n",
    "    # Remove the 'miss_pts_before' column\n",
    "    x = x[:,:,:-1]\n",
    "    \n",
    "    # Train-Val split\n",
    "    x_train,x_val = train_val_split(x,val_split)\n",
    "    return x_train.transpose(1,2),x_val.transpose(1,2)\n",
    "\n",
    "def sliding_windows(data, seq_length, line_num, x):\n",
    "    for i in range(len(data)-seq_length):\n",
    "        # Index considers previous lines\n",
    "        idx = i+line_num*(min_pt_count-seq_length)\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length,:3] # Assumes xyz are the first 3 features in scan_line_tensor\n",
    "        x[idx,:,:] = _x\n",
    "\n",
    "    return x\n",
    "\n",
    "def train_val_split(x,val_split):   \n",
    "    # Training/Validation split\n",
    "    # For now, we'll do the last part of the dataset as validation...shouldn't matter?\n",
    "    train_val_split_idx = int(x.shape[0]*(1-val_split))\n",
    "    x_train = x[:train_val_split_idx,:,:]\n",
    "    x_val = x[train_val_split_idx:,:,:]\n",
    "    \n",
    "    return x_train,x_val\n",
    "\n",
    "def add_mask(tensor,mask_pts_per_seq):\n",
    "    # Given a 3-D tensor of all ones, returns a mask_tensor of same shape \n",
    "    # with random masking determined by mask_pts_per_seq\n",
    "    mask_tensor = torch.ones(tensor.shape)\n",
    "    seq_len = mask_tensor.shape[1]\n",
    "    mask_idx = torch.randint(seq_len,(mask_tensor.shape[0],mask_pts_per_seq))\n",
    "    for i,m in enumerate(mask_idx):\n",
    "        mask_tensor[i,m,:] = 0\n",
    "    return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val = generate_samples(scan_line_tensor_norm,min_pt_count,seq_len,num_scan_lines,val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask tensor\n",
    "mask_train = add_mask(x_train,mask_pts_per_seq)\n",
    "mask_val = add_mask(x_val,mask_pts_per_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader class\n",
    "class LidarLstmDataset(udata.Dataset):\n",
    "    def __init__(self, x, mask):\n",
    "        super(LidarLstmDataset, self).__init__()\n",
    "        self.x = x\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.mask[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders\n",
    "train_dataset = LidarLstmDataset(x_train,mask_train)\n",
    "val_dataset = LidarLstmDataset(x_val,mask_val)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, num_workers=4, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track moving average of loss values\n",
    "train_meters = {name: utils.RunningAverageMeter(0.98) for name in ([\"train_loss\"])}\n",
    "valid_meters = {name: utils.AverageMeter() for name in ([\"valid_loss\"])}\n",
    "writer = SummaryWriter(log_dir=args.experiment_dir) if not args.no_visual else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([154517, 6, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 00:   0%|          | 0/4829 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 1, 5], expected input[32, 6, 64] to have 1 channels, but got 6 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c859e6dc8c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmask_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# only use the mask part of the outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mraw_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmask_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mraw_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask_inputs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-virtual-environments/data/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bfcnn/bias_free_denoising/models/lstm_unet1d_partialconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask_in)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mmask_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_bottom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# Layer by layer. ReLu's can't take the mask as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mprelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mprelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_saved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-virtual-environments/data/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bfcnn/bias_free_denoising/models/PartialConv1d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, mask_in)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_maskUpdater\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m# for mixed precision training, change 1e-8 to 1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 1, 5], expected input[32, 6, 64] to have 1 channels, but got 6 channels instead"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "for epoch in range(start_epoch, args.num_epochs):\n",
    "    if args.resume_training:\n",
    "        if epoch %10 == 0:\n",
    "            optimizer.param_groups[0][\"lr\"] /= 2\n",
    "            print('learning rate reduced by factor of 2')\n",
    "\n",
    "    train_bar = utils.ProgressBar(train_loader, epoch)\n",
    "    for meter in train_meters.values():\n",
    "        meter.reset()\n",
    "\n",
    "    for batch_id, (clean, mask) in enumerate(train_bar):\n",
    "        # dataloader returns [clean, mask] list\n",
    "        model.train()\n",
    "        global_step += 1\n",
    "        inputs = clean.to(device)\n",
    "        mask_inputs = mask.to(device)\n",
    "        # only use the mask part of the outputs\n",
    "        raw_outputs = model(inputs,mask_inputs)\n",
    "        outputs = (1-mask_inputs)*raw_outputs + mask_inputs*inputs\n",
    "        \n",
    "        # TO DO, only run loss on masked part of output\n",
    "        loss = F.mse_loss(outputs, inputs, reduction=\"sum\") / (inputs.size(0) * 2)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_meters[\"train_loss\"].update(loss)\n",
    "        train_bar.log(dict(**train_meters, lr=optimizer.param_groups[0][\"lr\"]), verbose=True)\n",
    "\n",
    "        if writer is not None and global_step % args.log_interval == 0:\n",
    "            writer.add_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], global_step)\n",
    "            writer.add_scalar(\"loss/train\", loss.item(), global_step)\n",
    "            gradients = torch.cat([p.grad.view(-1) for p in model.parameters() if p.grad is not None], dim=0)\n",
    "            writer.add_histogram(\"gradients\", gradients, global_step)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    if epoch % args.valid_interval == 0:\n",
    "        model.eval()\n",
    "        for meter in valid_meters.values():\n",
    "            meter.reset()\n",
    "\n",
    "        valid_bar = utils.ProgressBar(valid_loader)\n",
    "        \n",
    "        for sample_id, (clean, mask) in enumerate(valid_bar):\n",
    "            with torch.no_grad():\n",
    "                inputs = clean.to(device)\n",
    "                mask_inputs = mask.to(device)\n",
    "                # only use the mask part of the outputs\n",
    "                raw_output = model(inputs,mask_inputs)\n",
    "                output = (1-mask_inputs)*raw_output + mask_inputs*inputs\n",
    "\n",
    "                 # TO DO, only run loss on masked part of output\n",
    "                val_loss = F.mse_loss(outputs, inputs, reduction=\"sum\") / (inputs.size(0) * 2)\n",
    "\n",
    "                valid_meters[\"valid_loss\"].update(valid_psnr.item())\n",
    "\n",
    "                ### Uncomment these when finished\n",
    "                if writer is not None and sample_id < 10:\n",
    "                    image = torch.cat([inputs, torch.mul(inputs, mask_inputs), output], dim=0)\n",
    "                    image = torchvision.utils.make_grid(image.clamp(0, 1), nrow=3, normalize=False)\n",
    "                    writer.add_image(f\"valid_samples/{sample_id}\", image, global_step)\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"loss/valid\", valid_meters['valid_loss'].avg, global_step)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        logging.info(train_bar.print(dict(**train_meters, **valid_meters, lr=optimizer.param_groups[0][\"lr\"])))\n",
    "        utils.save_checkpoint(args, global_step, model, optimizer, score=valid_meters[\"valid_loss\"].avg, mode=\"max\")\n",
    "    scheduler.step()\n",
    "\n",
    "logging.info(f\"Done training! Best PSNR {utils.save_checkpoint.best_score:.3f} obtained after step {utils.save_checkpoint.best_step}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = models.build_model(args)\n",
    "# model3.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"))\n",
    "# model3.to(device)\n",
    "\n",
    "# model5 = models.build_model(args)\n",
    "# model5.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_08_13_20.pth\"))\n",
    "# model5.to(device)\n",
    "\n",
    "model10 = models.build_model(args)\n",
    "model10.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_10minsep_08_14_20.pth\"))\n",
    "model10.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of first predicted point\n",
    "Comparison to global mean, receptive field mean, next visible point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_sep = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def first_pt_stats(model,min_sep):\n",
    "    _,_,test_loader = data.build_dataset(args.dataset,\n",
    "                                                   args.n_data, \n",
    "                                                   batch_size=args.n_data,\n",
    "                                                   fix_datapoints=True,            \n",
    "                                                   min_sep = min_sep,\n",
    "                                                   test_num = 1)\n",
    "    print(\"Min_sep: {}\".format(min_sep))\n",
    "    print(\"*\"*30)\n",
    "    for batch_id,(clean,mask) in enumerate(test_loader):\n",
    "        print(\"Mean of clean signal: {:2.4f}\".format(clean.mean()))\n",
    "        outputs = model(clean.to(device),mask.to(device)).cpu()\n",
    "        print(\"Mean first value (min_sep=3): {:2.4f}\".format(outputs[:,:,0].mean()))\n",
    "\n",
    "    # Collect the \"means\" we're comparing to\n",
    "    mean_unmasked_sig = []\n",
    "    mean_rf_sig = []\n",
    "    first_unmasked = []\n",
    "\n",
    "    # Collect the diffs with the first value\n",
    "    mean_unmasked_sig_diff = []\n",
    "    mean_rf_sig_diff = []\n",
    "    first_unmasked_diff = []\n",
    "\n",
    "    mask_length = (64-mask.sum(axis=2))\n",
    "    for i in range(len(mask_length)):\n",
    "        # Mean of unmasked signal\n",
    "        mum = clean[i,0,int(mask_length[i]):].mean()\n",
    "        mean_unmasked_sig.append(mum)\n",
    "        # Mean of the unmasked receptive field \n",
    "        mrf = clean[i,0,int(mask_length[i]):21].mean()\n",
    "        mean_rf_sig.append(mrf)\n",
    "        # First unmasked value\n",
    "        fu = clean[i,0,int(mask_length[i])]\n",
    "        first_unmasked.append(fu)\n",
    "\n",
    "        # The diffs\n",
    "        mean_unmasked_sig_diff.append(abs(outputs[i,0,0]-mum).detach())\n",
    "        mean_rf_sig_diff.append(abs(outputs[i,0,0]-mrf).detach())\n",
    "        first_unmasked_diff.append(abs(outputs[i,0,0]-fu).detach())\n",
    "\n",
    "    print(\"Mean of full unmasked signal: {:2.4f}\".format(np.mean(mean_unmasked_sig)))\n",
    "    print(\"Mean of receptive field signal [0,21]: {:2.4f}\".format(np.mean(mean_rf_sig)))\n",
    "    print(\"Mean of first visible value after mask: {:2.4f}\".format(np.mean(first_unmasked)))\n",
    "\n",
    "    print(\"First predicted value mean diff: full unmasked signal: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(mean_unmasked_sig_diff),np.std(mean_unmasked_sig_diff)))\n",
    "    print(\"First predicted value mean diff: receptive field signal [0,21]: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(mean_rf_sig_diff),np.std(mean_rf_sig_diff)))\n",
    "    print(\"First predicted value mean diff: first visible value after mask: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(first_unmasked_diff),np.std(first_unmasked_diff)))\n",
    "    \n",
    "    df_list = [min_sep,np.mean(mean_unmasked_sig),np.mean(mean_rf_sig),np.mean(first_unmasked),\n",
    "              float(outputs[:,:,0].mean().detach()),\n",
    "              np.mean(mean_unmasked_sig_diff),np.std(mean_unmasked_sig_diff),\n",
    "              np.mean(mean_rf_sig_diff),np.std(mean_rf_sig_diff),\n",
    "              np.mean(first_unmasked_diff),np.std(first_unmasked_diff)\n",
    "              ]\n",
    "    # print(\"Mean absolute diff of first predicted value and first visible after mask: {:2.4f}\".format(np.mean(first_pred_unmasked_diff)))\n",
    "    ### min_sep = 3\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list3 = first_pt_stats(model3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list5 = first_pt_stats(model5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_list10 = first_pt_stats(model10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([df_list3,df_list5,df_list10],columns = ['min_sep',\\\n",
    "                                      'clean_sig_mean','receptive_field_mean',\\\n",
    "                                      'first_visible_mean','first_pred_mean',\\\n",
    "                                      'full_unmasked_diff_mean','full_unmasked_diff_sd',\\\n",
    "                                      'receptive_field_diff_mean','receptive_field_diff_sd',\\\n",
    "                                      'first_visible_diff_mean','first_visible_diff_sd'\n",
    "                                     ]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Best PSNR 28.560\n",
    "def mask_idx_f(mask):\n",
    "    mask_start = int(np.argmin(mask[0]))\n",
    "    mask_length = int((1-mask[0]).sum())\n",
    "    mask_idx = range(mask_start,mask_start+mask_length)\n",
    "     # No mask indices\n",
    "    before = np.arange(mask.shape[2])[:mask_start]\n",
    "    after = np.arange(mask.shape[2])[mask_start+mask_length:]\n",
    "    no_mask_idx = np.append(before,after)\n",
    "    return mask_idx,before, after, mask_length, mask_start\n",
    "\n",
    "def print_one(loader,model):\n",
    "    np.random.seed()\n",
    "    clean,mask = next(iter(loader))\n",
    "    outputs = model(clean.to(device),mask.to(device)).cpu()\n",
    "    \n",
    "    mask_idx,before_mask,after_mask,mask_length, mask_start = mask_idx_f(mask)\n",
    "\n",
    "    outputs[0] * (1-mask[0]) + clean[0]*mask[0]    \n",
    "\n",
    "    out = outputs[0] * (1-mask[0]) + clean[0]*mask[0]\n",
    "    print(\"Mask Length: {}\\tMask Start: {}\".format(mask_length,mask_start))\n",
    "    \n",
    "    plt.figure(figsize=[15,10])\n",
    "    plt.subplot(3,1,1)\n",
    "    plt.plot(clean[0,0,:],'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "    plt.title(\"True signal\")\n",
    "\n",
    "    plt.subplot(3,1,2)\n",
    "    masked = clean[0]*mask[0]\n",
    "    masked_plot = masked[:mask_start,]\n",
    "    plt.plot(before_mask,masked[0,before_mask],'xb')\n",
    "    plt.plot(after_mask,masked[0,after_mask],'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "\n",
    "    plt.title(\"Masked signal\")\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.plot(out[0,:].detach(),'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "\n",
    "    plt.title(\"Denoised signal\")\n",
    "    \n",
    "    # Mean of the visible signal\n",
    "    sig_mean = clean[0,0,mask_length:21].mean()\n",
    "    print(\"First mask value: {:2.4f}\\nMean of full signal: {:2.4f}\\nMean of visible signal: {:2.4f}\"\\\n",
    "          .format(out[0,0],clean[0,0,:21].mean(),sig_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loader is shuffled and allows test_num to force a certain mask shape\n",
    "_,_,test_loader = data.build_dataset(args.dataset,\n",
    "                                                   args.n_data, \n",
    "                                                   batch_size=args.n_data,\n",
    "                                                   fix_datapoints=True,            \n",
    "                                                   min_sep = 10,\n",
    "                                                   test_num = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "              1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,1.,0.,0.,0.,0.,0.,0.,0.,0., \n",
    "              0., 1., 1., 1.,1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,m = next(iter(test_loader))\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "MODEL_PATH = \"models/trained/unet1d_partialconv_100kdata_100epoch_08_21_20.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
